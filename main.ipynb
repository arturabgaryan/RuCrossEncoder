{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc23971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1900ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20de0051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>можно ли немного кофеина во время беременности</td>\n",
       "      <td>Мы мало что знаем о влиянии кофеина во время б...</td>\n",
       "      <td>Как правило, беременным женщинам безопасно ест...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>какие фрукты произрастают в Австралии</td>\n",
       "      <td>Passiflora herbertiana. Редкий плод маракуйи, ...</td>\n",
       "      <td>Орех кола - это плод кола, рода деревьев (кола...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>насколько велика канадская армия</td>\n",
       "      <td>Канадские вооруженные силы. 1 Первая крупномас...</td>\n",
       "      <td>Канадский институт здоровья врачей (CPHI) - эт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>виды фруктовых деревьев</td>\n",
       "      <td>Вишня. Вишневые деревья растут по всему миру. ...</td>\n",
       "      <td>Орех кола - это плод кола, рода деревьев (кола...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сколько калорий в день теряется при грудном вс...</td>\n",
       "      <td>Мало того, что грудное вскармливание лучше для...</td>\n",
       "      <td>Однако вам все равно нужно немного ниацина каж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>заболевания, вызываемые простейшими у животных</td>\n",
       "      <td>Трипаносомоз Это простейшее заболевание животн...</td>\n",
       "      <td>Антони ван Левенгук: Антони ван Левенгук, голл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>что такое биоразнообразие и лекарства</td>\n",
       "      <td>Биоразнообразие играет жизненно важную роль в ...</td>\n",
       "      <td>Обязательно сообщите своему лечащему врачу обо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>как рассчитать соответствие компании</td>\n",
       "      <td>Например, если компания соглашается обеспечить...</td>\n",
       "      <td>1 Нетто-зарплата также называется заработной п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>важная функция натрия -</td>\n",
       "      <td>1 Натрий играет большую роль в балансе жидкост...</td>\n",
       "      <td>Важность эстрогена. Эстрогены важны для поддер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>какой тип юриста мне нужен для дуи</td>\n",
       "      <td>1 Хорошая идея - вам, скорее всего, следует на...</td>\n",
       "      <td>После того, как вы закончите юридический факул...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     query  \\\n",
       "0           можно ли немного кофеина во время беременности   \n",
       "1                    какие фрукты произрастают в Австралии   \n",
       "2                         насколько велика канадская армия   \n",
       "3                                  виды фруктовых деревьев   \n",
       "4        сколько калорий в день теряется при грудном вс...   \n",
       "...                                                    ...   \n",
       "4999995     заболевания, вызываемые простейшими у животных   \n",
       "4999996              что такое биоразнообразие и лекарства   \n",
       "4999997               как рассчитать соответствие компании   \n",
       "4999998                            важная функция натрия -   \n",
       "4999999                 какой тип юриста мне нужен для дуи   \n",
       "\n",
       "                                                  positive  \\\n",
       "0        Мы мало что знаем о влиянии кофеина во время б...   \n",
       "1        Passiflora herbertiana. Редкий плод маракуйи, ...   \n",
       "2        Канадские вооруженные силы. 1 Первая крупномас...   \n",
       "3        Вишня. Вишневые деревья растут по всему миру. ...   \n",
       "4        Мало того, что грудное вскармливание лучше для...   \n",
       "...                                                    ...   \n",
       "4999995  Трипаносомоз Это простейшее заболевание животн...   \n",
       "4999996  Биоразнообразие играет жизненно важную роль в ...   \n",
       "4999997  Например, если компания соглашается обеспечить...   \n",
       "4999998  1 Натрий играет большую роль в балансе жидкост...   \n",
       "4999999  1 Хорошая идея - вам, скорее всего, следует на...   \n",
       "\n",
       "                                                  negative  \n",
       "0        Как правило, беременным женщинам безопасно ест...  \n",
       "1        Орех кола - это плод кола, рода деревьев (кола...  \n",
       "2        Канадский институт здоровья врачей (CPHI) - эт...  \n",
       "3        Орех кола - это плод кола, рода деревьев (кола...  \n",
       "4        Однако вам все равно нужно немного ниацина каж...  \n",
       "...                                                    ...  \n",
       "4999995  Антони ван Левенгук: Антони ван Левенгук, голл...  \n",
       "4999996  Обязательно сообщите своему лечащему врачу обо...  \n",
       "4999997  1 Нетто-зарплата также называется заработной п...  \n",
       "4999998  Важность эстрогена. Эстрогены важны для поддер...  \n",
       "4999999  После того, как вы закончите юридический факул...  \n",
       "\n",
       "[5000000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de8bce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128, indices=None):\n",
    "        \"\"\"\n",
    "        :param dataframe: pandas DataFrame с колонками ['query', 'positive', 'negative']\n",
    "        :param tokenizer: любой токенизатор из Transformers\n",
    "        :param max_length: максимальная длина токенизированных последовательностей\n",
    "        \"\"\"\n",
    "        self.dataset = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.indices = indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.indices is None:\n",
    "            return len(self.dataset) * 2  \n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            if self.indices is None:\n",
    "                total = len(self.dataset) * 2\n",
    "                indices = list(range(total))[idx]\n",
    "            else:\n",
    "                indices = self.indices[idx]\n",
    "            \n",
    "            return CustomDataset(\n",
    "                self.dataset,\n",
    "                self.tokenizer,\n",
    "                self.max_length,\n",
    "                indices=indices\n",
    "            )\n",
    "        \n",
    "        original_idx = self.indices[idx] if self.indices is not None else idx\n",
    "        \n",
    "        row_idx = original_idx // 2\n",
    "        pair_type = original_idx % 2\n",
    "        \n",
    "        example = self.dataset.iloc[row_idx]\n",
    "        query = example[\"query\"]\n",
    "        \n",
    "        if pair_type == 0:\n",
    "            text_b = example[\"positive\"]\n",
    "            label = 1\n",
    "        else:\n",
    "            text_b = example[\"negative\"]\n",
    "            label = 0\n",
    "        \n",
    "        encoded = self.tokenizer(\n",
    "            query,\n",
    "            text_b,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        for key in encoded:\n",
    "            encoded[key] = encoded[key].squeeze(0)\n",
    "        \n",
    "        encoded[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1811d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "batch_size = 128\n",
    "tokenizer_name = './tokenizer'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "tokenizer.model_max_length = 1024\n",
    "\n",
    "\n",
    "train_data = CustomDataset(\n",
    "    dataframe=data,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "train = train_data[:1000000]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab543cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1, 35099,   634,  1982,  5421,   622,   565,   782, 26011,     2,\n",
       "            2,  3284,  2715,   368,  6384,   288,  4184,  2190,  5421,   622,\n",
       "          565,   782, 26011,   324,  1118,   289,  5977,  4635,    18,   987,\n",
       "          368,  1667,  1129, 35455,  8560,    16,  2104,   388,   908,  2178,\n",
       "         2391,  1067,    18,  1194,   388,  9649, 21166,    16,  3661,  4228,\n",
       "         4357,  5421,   622,  1954,  2614, 32867, 16660,  2391,  1067,    18,\n",
       "          850,  4533,  3477,    16,  2617, 21614,   281,  6140,   655,  5421,\n",
       "        45064,   514,   386,    28, 20038,  1959,   694,  1853,  6140,   655,\n",
       "         5421, 45064,  2692, 20038,  1959,    18,     2,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(1)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a98d7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, dropout_prob=0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.act = nn.GELU()\n",
    "        self.layernorm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.layernorm(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc2(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class CrossEncoder(nn.Module):\n",
    "    def __init__(self, pretrained_model_name: str, num_labels: int = 2, dropout_prob: float = 0.1):\n",
    "        super(CrossEncoder, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        self.classifier = Classifier(self.encoder.config.hidden_size, num_labels, dropout_prob)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "            pooled_output = outputs.pooler_output\n",
    "        else:\n",
    "            pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.classifier.fc2.out_features == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.classifier.fc2.out_features), labels.view(-1))\n",
    "        \n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "pretrained_model_name = \"./crossenc\" \n",
    "model = CrossEncoder(pretrained_model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37f2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "         \n",
    "weight_decay       = 0.01                                 \n",
    "warmup_ratio       = 0.1          \n",
    "max_grad_norm      = 1.0            \n",
    "layerwise_decay    = 0.8           \n",
    "fp16               = True\n",
    "accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0523cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.config.max_position_embeddings = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ae352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1/10: 100%|\u001b[38;2;252;107;3m██████████\u001b[0m| 7813/7813 [34:39<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря (loss) за эпоху: 0.5470\n",
      "Чекпоинт сохранен: ./checkpoints/checkpoint_epoch_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 2/10: 100%|\u001b[38;2;252;107;3m██████████\u001b[0m| 7813/7813 [34:57<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря (loss) за эпоху: 0.4360\n",
      "Чекпоинт сохранен: ./checkpoints/checkpoint_epoch_1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 3/10: 100%|\u001b[38;2;252;107;3m██████████\u001b[0m| 7813/7813 [34:32<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря (loss) за эпоху: 0.3129\n",
      "Чекпоинт сохранен: ./checkpoints/checkpoint_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 4/10: 100%|\u001b[38;2;252;107;3m██████████\u001b[0m| 7813/7813 [34:28<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря (loss) за эпоху: 0.2088\n",
      "Чекпоинт сохранен: ./checkpoints/checkpoint_epoch_3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 5/10: 100%|\u001b[38;2;252;107;3m██████████\u001b[0m| 7813/7813 [34:51<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря (loss) за эпоху: 0.1407\n",
      "Чекпоинт сохранен: ./checkpoints/checkpoint_epoch_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 6/10: 100%|\u001b[38;2;252;107;3m██████████\u001b[0m| 7813/7813 [34:32<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя потеря (loss) за эпоху: 0.0983\n",
      "Чекпоинт сохранен: ./checkpoints/checkpoint_epoch_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 7/10:  25%|\u001b[38;2;252;107;3m██▌       \u001b[0m| 1974/7813 [08:44<25:43,  3.78it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "resume_from_checkpoint = None\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 3e-5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-6\n",
    ")\n",
    "\n",
    "total_steps = len(train_loader) * epochs\n",
    "warmup_steps = int(warmup_ratio * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "start_epoch = 0\n",
    "if resume_from_checkpoint and os.path.isfile(resume_from_checkpoint):\n",
    "    print(f\"Загружаем чекпоинт: {resume_from_checkpoint}\")\n",
    "    checkpoint = torch.load(resume_from_checkpoint, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Обучение возобновлено с эпохи {start_epoch}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(train_loader, colour='#fc6b03', desc=f'Эпоха {epoch+1}/{epochs}'):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        token_type_ids = batch.get(\"token_type_ids\")\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=fp16):\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs[\"loss\"] / accumulation_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Средняя потеря (loss) за эпоху: {avg_loss:.4f}\")\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Чекпоинт сохранен: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57cbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|\u001b[38;2;53;252;3m██████████\u001b[0m| 1563/1563 [08:38<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6882\n",
      "Precision: 0.6359\n",
      "Recall: 0.8804\n",
      "F1 Score: 0.7385\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.50      0.61    100000\n",
      "           1       0.64      0.88      0.74    100000\n",
      "\n",
      "    accuracy                           0.69    200000\n",
      "   macro avg       0.72      0.69      0.68    200000\n",
      "weighted avg       0.72      0.69      0.68    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "max_length = 128\n",
    "val_batch_size = 128\n",
    "\n",
    "test = train_data[2000000:2200000]\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=val_batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader,colour='#35fc03',desc='validation'):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        token_type_ids = batch.get(\"token_type_ids\")\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6d3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./pretrained/MSmarco and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at ./pretrained/BGE and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка модели: Russian-msmarco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|\u001b[38;2;26;210;219m██████████\u001b[0m| 157/157 [00:39<00:00,  3.94it/s]\n",
      "/home/avabgaryan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5000\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 Score:  0.0000\n",
      "------------------------------\n",
      "Оценка модели: BGE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|\u001b[38;2;26;210;219m██████████\u001b[0m| 157/157 [00:40<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5000\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 Score:  0.0000\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/avabgaryan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "model_ids = {\n",
    "    \"Russian-msmarco\": \"./pretrained/MSmarco\",\n",
    "    \"BGE\": \"./pretrained/BGE\",\n",
    "}\n",
    "\n",
    "models = {}\n",
    "tokenizers = {}\n",
    "for name, model_id in model_ids.items():\n",
    "    tokenizers[name] = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    models[name] = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "batch_size = 128\n",
    "max_length = 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test = train_data[100000:120000]\n",
    "\n",
    "for name in models.keys():\n",
    "    print(f\"Оценка модели: {name}\")\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    model = models[name].to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader,colour='#1ad2db',desc='validation'):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            token_type_ids = batch.get(\"token_type_ids\")\n",
    "            if token_type_ids is not None:\n",
    "                token_type_ids = token_type_ids.to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
