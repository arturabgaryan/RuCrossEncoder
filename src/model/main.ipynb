{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc23971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup, AutoModelForSequenceClassification\n",
    "import datasets\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import ir_measures\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_dataset('unicamp-dl/mmarco', 'russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20de0051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>можно ли немного кофеина во время беременности</td>\n",
       "      <td>Мы мало что знаем о влиянии кофеина во время б...</td>\n",
       "      <td>Как правило, беременным женщинам безопасно ест...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>какие фрукты произрастают в Австралии</td>\n",
       "      <td>Passiflora herbertiana. Редкий плод маракуйи, ...</td>\n",
       "      <td>Орех кола - это плод кола, рода деревьев (кола...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>насколько велика канадская армия</td>\n",
       "      <td>Канадские вооруженные силы. 1 Первая крупномас...</td>\n",
       "      <td>Канадский институт здоровья врачей (CPHI) - эт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>виды фруктовых деревьев</td>\n",
       "      <td>Вишня. Вишневые деревья растут по всему миру. ...</td>\n",
       "      <td>Орех кола - это плод кола, рода деревьев (кола...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сколько калорий в день теряется при грудном вс...</td>\n",
       "      <td>Мало того, что грудное вскармливание лучше для...</td>\n",
       "      <td>Однако вам все равно нужно немного ниацина каж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>заболевания, вызываемые простейшими у животных</td>\n",
       "      <td>Трипаносомоз Это простейшее заболевание животн...</td>\n",
       "      <td>Антони ван Левенгук: Антони ван Левенгук, голл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>что такое биоразнообразие и лекарства</td>\n",
       "      <td>Биоразнообразие играет жизненно важную роль в ...</td>\n",
       "      <td>Обязательно сообщите своему лечащему врачу обо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>как рассчитать соответствие компании</td>\n",
       "      <td>Например, если компания соглашается обеспечить...</td>\n",
       "      <td>1 Нетто-зарплата также называется заработной п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>важная функция натрия -</td>\n",
       "      <td>1 Натрий играет большую роль в балансе жидкост...</td>\n",
       "      <td>Важность эстрогена. Эстрогены важны для поддер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>какой тип юриста мне нужен для дуи</td>\n",
       "      <td>1 Хорошая идея - вам, скорее всего, следует на...</td>\n",
       "      <td>После того, как вы закончите юридический факул...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     query  \\\n",
       "0           можно ли немного кофеина во время беременности   \n",
       "1                    какие фрукты произрастают в Австралии   \n",
       "2                         насколько велика канадская армия   \n",
       "3                                  виды фруктовых деревьев   \n",
       "4        сколько калорий в день теряется при грудном вс...   \n",
       "...                                                    ...   \n",
       "4999995     заболевания, вызываемые простейшими у животных   \n",
       "4999996              что такое биоразнообразие и лекарства   \n",
       "4999997               как рассчитать соответствие компании   \n",
       "4999998                            важная функция натрия -   \n",
       "4999999                 какой тип юриста мне нужен для дуи   \n",
       "\n",
       "                                                  positive  \\\n",
       "0        Мы мало что знаем о влиянии кофеина во время б...   \n",
       "1        Passiflora herbertiana. Редкий плод маракуйи, ...   \n",
       "2        Канадские вооруженные силы. 1 Первая крупномас...   \n",
       "3        Вишня. Вишневые деревья растут по всему миру. ...   \n",
       "4        Мало того, что грудное вскармливание лучше для...   \n",
       "...                                                    ...   \n",
       "4999995  Трипаносомоз Это простейшее заболевание животн...   \n",
       "4999996  Биоразнообразие играет жизненно важную роль в ...   \n",
       "4999997  Например, если компания соглашается обеспечить...   \n",
       "4999998  1 Натрий играет большую роль в балансе жидкост...   \n",
       "4999999  1 Хорошая идея - вам, скорее всего, следует на...   \n",
       "\n",
       "                                                  negative  \n",
       "0        Как правило, беременным женщинам безопасно ест...  \n",
       "1        Орех кола - это плод кола, рода деревьев (кола...  \n",
       "2        Канадский институт здоровья врачей (CPHI) - эт...  \n",
       "3        Орех кола - это плод кола, рода деревьев (кола...  \n",
       "4        Однако вам все равно нужно немного ниацина каж...  \n",
       "...                                                    ...  \n",
       "4999995  Антони ван Левенгук: Антони ван Левенгук, голл...  \n",
       "4999996  Обязательно сообщите своему лечащему врачу обо...  \n",
       "4999997  1 Нетто-зарплата также называется заработной п...  \n",
       "4999998  Важность эстрогена. Эстрогены важны для поддер...  \n",
       "4999999  После того, как вы закончите юридический факул...  \n",
       "\n",
       "[5000000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128, indices=None):\n",
    "        \"\"\"\n",
    "        :param dataframe: pandas DataFrame с колонками ['query', 'positive', 'negative']\n",
    "        :param tokenizer: любой токенизатор из Transformers\n",
    "        :param max_length: максимальная длина токенизированных последовательностей\n",
    "        \"\"\"\n",
    "        self.dataset = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.indices = indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.indices is None:\n",
    "            return len(self.dataset) * 2  \n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            if self.indices is None:\n",
    "                total = len(self.dataset) * 2\n",
    "                indices = list(range(total))[idx]\n",
    "            else:\n",
    "                indices = self.indices[idx]\n",
    "            \n",
    "            return CustomDataset(\n",
    "                self.dataset,\n",
    "                self.tokenizer,\n",
    "                self.max_length,\n",
    "                indices=indices\n",
    "            )\n",
    "        \n",
    "        original_idx = self.indices[idx] if self.indices is not None else idx\n",
    "        \n",
    "        row_idx = original_idx // 2\n",
    "        pair_type = original_idx % 2\n",
    "        \n",
    "        example = self.dataset.iloc[row_idx]\n",
    "        query = example[\"query\"]\n",
    "        \n",
    "        if pair_type == 0:\n",
    "            text_b = example[\"positive\"]\n",
    "            label = 1\n",
    "        else:\n",
    "            text_b = example[\"negative\"]\n",
    "            label = 0\n",
    "        \n",
    "        encoded = self.tokenizer(\n",
    "            query,\n",
    "            text_b,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        for key in encoded:\n",
    "            encoded[key] = encoded[key].squeeze(0)\n",
    "        \n",
    "        encoded[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1811d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "batch_size = 128\n",
    "tokenizer_name = './tokenizer'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "tokenizer.model_max_length = 1024\n",
    "\n",
    "\n",
    "train_data = CustomDataset(\n",
    "    dataframe=data,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "train = train_data[:1000000]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a98d7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels, dropout_prob=0.1):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.act = nn.GELU()\n",
    "        self.layernorm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.layernorm(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc2(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class CrossEncoder(nn.Module):\n",
    "    def __init__(self, pretrained_model_name: str, num_labels: int = 2, dropout_prob: float = 0.1):\n",
    "        super(CrossEncoder, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        self.classifier = Classifier(self.encoder.config.hidden_size, num_labels, dropout_prob)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        if hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "            pooled_output = outputs.pooler_output\n",
    "        else:\n",
    "            pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.classifier.fc2.out_features == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.classifier.fc2.out_features), labels.view(-1))\n",
    "        \n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "pretrained_model_name = \"./crossenc\" \n",
    "model = CrossEncoder(pretrained_model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay       = 0.01                                 \n",
    "warmup_ratio       = 0.1          \n",
    "max_grad_norm      = 1.0            \n",
    "layerwise_decay    = 0.8           \n",
    "fp16               = True\n",
    "accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0523cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.config.max_position_embeddings = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "resume_from_checkpoint = None\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 3e-5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1e-6\n",
    ")\n",
    "\n",
    "total_steps = len(train_loader) * epochs\n",
    "warmup_steps = int(warmup_ratio * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "start_epoch = 0\n",
    "if resume_from_checkpoint and os.path.isfile(resume_from_checkpoint):\n",
    "    print(f\"Загружаем чекпоинт: {resume_from_checkpoint}\")\n",
    "    checkpoint = torch.load(resume_from_checkpoint, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Обучение возобновлено с эпохи {start_epoch}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(train_loader, colour='#fc6b03', desc=f'Эпоха {epoch+1}/{epochs}'):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        token_type_ids = batch.get(\"token_type_ids\")\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=fp16):\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs[\"loss\"] / accumulation_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Средняя потеря (loss) за эпоху: {avg_loss:.4f}\")\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}.pt\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Чекпоинт сохранен: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_length = 128\n",
    "val_batch_size = 128\n",
    "\n",
    "test = train_data[2000000:2200000]\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=val_batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader,colour='#35fc03',desc='validation'):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        token_type_ids = batch.get(\"token_type_ids\")\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_ids = {\n",
    "    \"Russian-msmarco\": \"path/to/weights\",\n",
    "    \"FRIDA\": \"path/to/weights\",\n",
    "    'RuCrossEncoder': \"path/to/weights\"\n",
    "}\n",
    "\n",
    "models = {}\n",
    "tokenizers = {}\n",
    "for name, model_id in model_ids.items():\n",
    "    tokenizers[name] = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    models[name] = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "\n",
    "batch_size = 128\n",
    "max_length = 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test = train_data[10000000:12000000]\n",
    "\n",
    "for name in models.keys():\n",
    "    print(f\"Оценка модели: {name}\")\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    model = models[name].to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader,colour='#1ad2db',desc='validation'):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            token_type_ids = batch.get(\"token_type_ids\")\n",
    "            if token_type_ids is not None:\n",
    "                token_type_ids = token_type_ids.to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f27394",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"name of model/checkpoint of pretrained\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "valid_data = pd.read_excel('name of generated dataset')\n",
    "\n",
    "class RankingDataset(Dataset):\n",
    "    def __init__(self, queries):\n",
    "        \"\"\"\n",
    "        queries: список словарей формата:\n",
    "            {\n",
    "                \"query\": \"текст запроса\",\n",
    "                \"docs\": [\n",
    "                    {\"text\": \"текст документа\", \"relevance\": уровень_релевантности},\n",
    "                    ...\n",
    "                ]\n",
    "            }\n",
    "        \"\"\"\n",
    "        self.queries = queries\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.queries[idx]\n",
    "\n",
    "# Пример данных\n",
    "# test_queries = [\n",
    "#     {\n",
    "#         \"query\": \"как часто ходить к стоматологу?\",\n",
    "#         \"docs\": [\n",
    "#             {\"text\": \"рекомендуется каждые 6 месяцев\", \"relevance\": 2},\n",
    "#             {\"text\": \"дядя Вася стоматолог\", \"relevance\": 0},\n",
    "#             {\"text\": \"оптимально раз в полгода\", \"relevance\": 2},\n",
    "#             {\"text\": \"зубы надо чистить ежедневно\", \"relevance\": 1},\n",
    "#         ]\n",
    "#     },\n",
    "#     # ... другие запросы\n",
    "# ]\n",
    "\n",
    "dataset = RankingDataset(valid_data)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "all_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, desc=\"Обработка запросов\"):\n",
    "        query_data = batch[0] if isinstance(batch, list) else batch\n",
    "        query_text = str(query_data[\"query\"]) \n",
    "        docs = query_data[\"docs\"]\n",
    "        \n",
    "        texts = []\n",
    "        for doc in docs:\n",
    "            doc_text = str(doc.get(\"text\", \"\"))  \n",
    "            texts.append((query_text, doc_text))\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            [t[0] for t in texts],\n",
    "            [t[1] for t in texts],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "       \n",
    "        outputs = model(**inputs)\n",
    "        scores = torch.sigmoid(outputs.logits).cpu().numpy().flatten()\n",
    "        \n",
    "        query_results = {\n",
    "            \"query\": query_text,\n",
    "            \"scores\": scores,\n",
    "            \"true_relevance\": [int(doc[\"relevance\"]) for doc in docs]\n",
    "        }\n",
    "        all_results.append(query_results)\n",
    "\n",
    "qrels = []\n",
    "run = []\n",
    "\n",
    "for result in all_results:\n",
    "    query = result[\"query\"]\n",
    "    for i, (score, rel) in enumerate(zip(result[\"scores\"], result[\"true_relevance\"])):\n",
    "        qrels.append(ir_measures.Qrel(query, f\"doc_{i}\", rel))\n",
    "        run.append(ir_measures.ScoredDoc(query, f\"doc_{i}\", float(score)))\n",
    "\n",
    "metrics = ir_measures.calc_aggregate(\n",
    "    [\n",
    "        ir_measures.nDCG@10,\n",
    "        ir_measures.MAP@100,\n",
    "        ir_measures.Recall@100,\n",
    "    ],\n",
    "    qrels,\n",
    "    run\n",
    ")\n",
    "\n",
    "print(\"\\nРезультаты оценки:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
